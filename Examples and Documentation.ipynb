{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from onepiecepredictor.OnePieceClassifier import OnePieceClassifier\n",
    "from onepiecepredictor.MultiModelsClassifier import MultiModelsClassifier\n",
    "from onepiecepredictor.OnePieceRegression import OnePieceRegression\n",
    "from onepiecepredictor.MultiModelsRegression import MultiModelsRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Small package for hyper paramter tuning pipelining and comparing multiple models performance.\n",
    "\n",
    "### Its a wrapper around sklearn, xgboost, catboost, imblearn packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currently Supports 7 models for classification:\n",
    "   * LOGISTIC -> logistic regression, uses LogisticRegression class from sklearn package.\n",
    "   * RF -> Random Forest, uses RandomForestClassifier class from sklearn package. \n",
    "   * SVM -> Support Vector Machine, uses SVC class from sklearn package.\n",
    "   * KNN -> K Nearest Neighbours, uses KNeighborsClassifier class from sklearn package.\n",
    "   * ADABOOST -> Adaptive boosting, uses AdaBoostClassifier class from sklearn package.\n",
    "   * XGBOOST -> Uses XGBClassifier class from xgboost package.\n",
    "   * CATBOOST -> Uses CatBoostClassifier from catboost package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass one of the key words mentioned above for OnePieceClassifier using the model paramter to use respective model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramters Information for OnePieceClassifier Class\n",
    "\n",
    "* X -> array-like(supported by Sklearn). If testTrainSplit is passed, this will be split into train and test\n",
    "* Y -> array-like(supported by Sklearn). If testTrainSplit is passed, this will be split into train and test\n",
    "* model -> string Currently supported models: LOGISTIC,RF,SVM,KNN,ADABOOST,XGBOOST,CATBOOST\n",
    "* testX -> array-like(supported by Sklearn), test data. Ignored if testTrainSplit is passed\n",
    "* testY -> array-like(supported by Sklearn), test data. Ignored if testTrainSplit is passed\n",
    "* testTrainSplit -> float, ratio passed will be the amount of test data.\n",
    "* stratify -> bool, used to perform stratified splitting. If passed data will be split based on Y.\n",
    "* hyperParams -> dictionary, Hyper parameters specific to the model passed. If passed CV is performed.\n",
    "* performCV -> bool, Used when hyperParams not passed to perform plain CV.\n",
    "* folds -> int, No of folds to be used for CV.\n",
    "* applySmote -> bool, To apply smote to oversample the data. Pass only one of applySmote or underSample\n",
    "* underSample -> bool, To randomly undersample the majority data.\n",
    "* sampling -> str, Values supported by SMOTE, RandomUnderSampler classes in imblearn library.\n",
    "* scoring -> str, Evaluation metric. Currently supported values: accuracy,balanced_accuracy,f1,precision,recall,roc_auc. If not passed accuracy is used.\n",
    "* targetEncodeCols -> List. List of columns to target encode.\n",
    "* modelParams -> dictionary, Any model specific parameters can be passed as dictionary.\n",
    "* multiClass -> Pass true in case of multiclass classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods in OnePieceClassifier class\n",
    "\n",
    "* fit() -> For training.\n",
    "* predict() -> For Predicting. Returns score and predictions.\n",
    "* newDataPredict(testData) -> For getting the predictions on completely new data. Returns new predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification HyperParamters With corss Validation and startified splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParams = {\n",
    "        'gamma': [0.25, 1],\n",
    "        'max_depth': [3, 4]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "Y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return after splitting not smote or undersample\n"
     ]
    }
   ],
   "source": [
    "op = OnePieceClassifier(X, Y, \"XGBOOST\",testTrainSplit = 0.3, \n",
    "                        stratify = True, hyperParams = hyperParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Grid Search Scores\n",
      "0.9547784810126583 {'gamma': 0.25, 'max_depth': 3}\n",
      "0.9547468354430381 {'gamma': 0.25, 'max_depth': 4}\n",
      "0.9572784810126583 {'gamma': 1, 'max_depth': 3}\n",
      "0.9472151898734177 {'gamma': 1, 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "op.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST accuracy 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "score, preds = op.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9824561403508771"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicitly pass train and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct return\n",
      "Cross Validation Grid Search Scores\n",
      "0.9547784810126583 {'gamma': 0.25, 'max_depth': 3}\n",
      "0.9547468354430381 {'gamma': 0.25, 'max_depth': 4}\n",
      "0.9572784810126583 {'gamma': 1, 'max_depth': 3}\n",
      "0.9472151898734177 {'gamma': 1, 'max_depth': 4}\n",
      "XGBOOST accuracy 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "Y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify=Y,test_size=0.3, random_state = 7)\n",
    "op = OnePieceClassifier(X_train, y_train, \"XGBOOST\", testX = X_test, testY = y_test\n",
    "                         ,hyperParams = hyperParams)\n",
    "op.fit()\n",
    "score, preds = op.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use  any model with specific model paramters explicitly, pass a dictionary using modelParams parameter.\n",
    "### For example to use  random forest with 'criterion' as entropy instead of default gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "Y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {'criterion' : 'entropy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParams = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return after splitting not smote or undersample\n"
     ]
    }
   ],
   "source": [
    "op = OnePieceClassifier(X, Y, \"RF\",testTrainSplit = 0.2, \n",
    "                        stratify = True, hyperParams = hyperParams, scoring = 'f1',modelParams = modelParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Grid Search Scores\n",
      "0.9584491475733954 {'max_depth': 2, 'n_estimators': 100}\n",
      "0.9568034403850707 {'max_depth': 2, 'n_estimators': 200}\n",
      "0.9617859967011716 {'max_depth': 3, 'n_estimators': 100}\n",
      "0.9617859967011716 {'max_depth': 3, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "op.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF f1 0.9583333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9583333333333334,\n",
       " array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "        1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "        1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To compare performance of multiple classification models with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MultiModelsClassifier(X, Y, testTrainSplit = 0.3, \n",
    "                        stratify = True, scoring = 'accuracy', performCV = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return after splitting not smote or undersample\n",
      "Direct return\n",
      "Plain Cross Validation Scores\n",
      "[0.9375     0.9375     0.95       0.94936709 0.92405063]\n",
      "LOGISTIC accuracy 0.9532163742690059\n",
      "Direct return\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain Cross Validation Scores\n",
      "[0.9875     0.9625     0.95       0.94936709 0.97468354]\n",
      "RF accuracy 0.9649122807017544\n",
      "Direct return\n",
      "Plain Cross Validation Scores\n",
      "[0.9125     0.9        0.8875     0.88607595 0.91139241]\n",
      "SVM accuracy 0.935672514619883\n",
      "Direct return\n",
      "Plain Cross Validation Scores\n",
      "[0.8875     0.95       0.9        0.92405063 0.93670886]\n",
      "KNN accuracy 0.9473684210526315\n",
      "Direct return\n",
      "Plain Cross Validation Scores\n",
      "[0.9625     0.9375     0.9375     0.91139241 0.97468354]\n",
      "ADABOOST accuracy 0.9415204678362573\n",
      "Direct return\n",
      "Plain Cross Validation Scores\n",
      "[0.95       0.9375     0.975      0.93670886 0.97468354]\n",
      "XGBOOST accuracy 0.9707602339181286\n",
      "Direct return\n",
      "Plain Cross Validation Scores\n",
      "[0.975      0.9625     0.9625     0.97468354 0.98734177]\n",
      "CATBOOST accuracy 0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "results = mc.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOGISTIC': 0.9532163742690059, 'RF': 0.9649122807017544, 'SVM': 0.935672514619883, 'KNN': 0.9473684210526315, 'ADABOOST': 0.9415204678362573, 'XGBOOST': 0.9707602339181286, 'CATBOOST': 0.9766081871345029}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Imbalanced data, with oversampling. Oversample minorty class to 40% from 10% and test on new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_classification(n_classes=2, class_sep=2,\n",
    "weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
    "n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return after smote\n"
     ]
    }
   ],
   "source": [
    "op = OnePieceClassifier(X, Y, \"LOGISTIC\",testTrainSplit = 0.2, applySmote = True, sampling = 0.4,\n",
    "                        stratify = True, scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC f1 0.994475138121547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.994475138121547,\n",
       " array([0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_classification(n_classes=2, class_sep=2,\n",
    "weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
    "n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = op.newDataPredict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currently Supports 7 models for classification:\n",
    "   * LINEAR -> linear regression, uses LinearRegression class from sklearn package.\n",
    "   * RF -> Random Forest, uses RandomForestRegressor class from sklearn package. \n",
    "   * SVM -> Support Vector Machine, uses SVR class from sklearn package.\n",
    "   * KNN -> K Nearest Neighbours, uses KNeighborsRegressor class from sklearn package.\n",
    "   * ADABOOST -> Adaptive boosting, uses AdaBoostRegressor class from sklearn package.\n",
    "   * XGBOOST -> Uses XGBRegressor class from xgboost package.\n",
    "   * CATBOOST -> Uses CatBoostRegressor from catboost package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramters Information for OnePieceRegression Class\n",
    "\n",
    "* X -> array-like(supported by Sklearn). If testTrainSplit is passed, this will be split into train and test\n",
    "* Y -> array-like(supported by Sklearn). If testTrainSplit is passed, this will be split into train and test\n",
    "* model -> string Currently supported models: LOGISTIC,RF,SVM,KNN,ADABOOST,XGBOOST,CATBOOST\n",
    "* testX -> array-like(supported by Sklearn), test data. Ignored if testTrainSplit is passed\n",
    "* testY -> array-like(supported by Sklearn), test data. Ignored if testTrainSplit is passed\n",
    "* testTrainSplit -> float, ratio passed will be the amount of test data.\n",
    "* hyperParams -> dictionary, Hyper parameters specific to the model passed. If passed CV is performed.\n",
    "* performCV -> bool, Used when hyperParams not passed to perform plain CV.\n",
    "* folds -> int, No of folds to be used for CV.\n",
    "* scoring -> str, Evaluation metric. Currently supported values: r2,neg_mean_squared_error. If not passed r2 is used.\n",
    "* targetEncodeCols -> List. List of columns to target encode.\n",
    "* modelParams -> dictionary, Any model specific parameters can be passed as dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods in OnePieceRegression class\n",
    "\n",
    "* fit() -> For training.\n",
    "* predict() -> For Predicting. Returns score and predictions.\n",
    "* newDataPredict(testData) -> For getting the predictions on completely new data. Returns new predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with corss Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_boston()\n",
    "X = data.data\n",
    "Y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "oreg = OnePieceRegression(X, Y, \"SVM\", testTrainSplit = 0.1, performCV = True, folds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain Cross Validation Scores\n",
      "[0.15438665 0.10650229 0.26598772]\n"
     ]
    }
   ],
   "source": [
    "oreg.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM r2 0.34925488510037106\n"
     ]
    }
   ],
   "source": [
    "score, preds = oreg.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34925488510037106"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.54673206, 24.0901247 , 23.28084315, 22.62159566, 13.16347039,\n",
       "       15.40087197, 15.4833122 , 22.44323748, 23.76091211, 13.37660897,\n",
       "       15.08671352, 22.13407802, 15.42715015, 20.36897878, 25.20474867,\n",
       "       15.77979286, 22.97590132, 23.36234758, 20.38150564, 23.27257591,\n",
       "       15.50425217, 22.75466495, 23.60611513, 22.13589269, 19.7066852 ,\n",
       "       13.26357132, 24.37972782, 22.75251023, 23.59303909, 23.99226643,\n",
       "       15.18731668, 22.66819372, 23.33501333, 13.38457154, 23.86017145,\n",
       "       19.17809459, 20.65670891, 13.30587608, 22.68438372, 23.2121177 ,\n",
       "       23.22551318, 15.14903014, 19.01176745, 20.84939127, 15.66299515,\n",
       "       13.27407679, 22.28021024, 15.67954225, 16.92536172, 13.50496673,\n",
       "       23.12350002])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To compare performance of multiple classification models with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_boston()\n",
    "X = data.data\n",
    "Y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = MultiModelsRegression(X, Y, testTrainSplit = 0.1,performCV = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain Cross Validation Scores\n",
      "[0.60751038 0.70491158 0.65270854 0.74562459 0.80643389]\n",
      "LINEAR r2 0.7411608113128136\n",
      "Plain Cross Validation Scores\n",
      "[0.77029406 0.88816969 0.8136425  0.89774958 0.91415022]\n",
      "RF r2 0.8984647766384302\n",
      "Plain Cross Validation Scores\n",
      "[0.11621987 0.11101511 0.05166818 0.24898521 0.2687132 ]\n",
      "SVM r2 0.34925488510037106\n",
      "Plain Cross Validation Scores\n",
      "[0.4230675  0.64771465 0.14544463 0.63244563 0.63013816]\n",
      "KNN r2 0.6056016145431431\n",
      "Plain Cross Validation Scores\n",
      "[0.74122869 0.81921018 0.83943351 0.87509177 0.86914851]\n",
      "ADABOOST r2 0.8872523509716893\n",
      "Plain Cross Validation Scores\n",
      "[0.82610214 0.86961755 0.82893475 0.89717366 0.88435955]\n",
      "XGBOOST r2 0.8985230224379863\n",
      "Plain Cross Validation Scores\n",
      "[0.83943697 0.88791814 0.85577629 0.92789034 0.90279473]\n",
      "CATBOOST r2 0.9339575147177712\n"
     ]
    }
   ],
   "source": [
    "results = mr.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LINEAR': 0.7411608113128136,\n",
       " 'RF': 0.8984647766384302,\n",
       " 'SVM': 0.34925488510037106,\n",
       " 'KNN': 0.6056016145431431,\n",
       " 'ADABOOST': 0.8872523509716893,\n",
       " 'XGBOOST': 0.8985230224379863,\n",
       " 'CATBOOST': 0.9339575147177712}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
